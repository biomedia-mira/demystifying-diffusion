\newpage
\section{Discussion}
%
Despite the growing popularity of diffusion models, gaining a deep understanding of the model class remained somewhat elusive for the uninitiated in non-equilibrium statistical physics. With that in mind, we have presented a more straightforward introduction to diffusion models using directed graphical modelling and variational inference principles, which imposes relatively fewer prerequisites on the reader.

Our exposition began with a basic review of latent variable models like VAEs. We then reviewed their deep hierarchical counterparts and established a unifying graphical modelling-based perspective on their connection with diffusion models. We showed that diffusion models share a specific \textit{top-down} latent variable hierarchy structure with ladder networks~\citep{valpola2015neural} and top-down inference HVAEs~\citep{sonderby2016ladder}, which among other things explains why they share the same optimization objective.
Although introducing additional (auxiliary) latent variables significantly improves the flexibility of both the inference and generative models, it comes with additional challenges. We highlighted the difficulties with using purely \textit{bottom-up} inference procedures in deep latent variable hierarchies, including \textit{posterior collapse} for instance, whereby the posterior distribution (of the top-most layer, say) may collapse to a standard Gaussian prior, failing to learn meaningful representations and deactivating latent variables. Both~\cite{burda2015importance} and~\cite{sohl2015deep} point to the asymmetry between the associated generative and inference models in HVAEs as a source of difficulty in training the inference model efficiently, since there is no way to express each term in the variational lower bound as an expectation under a distribution over a single latent variable.~\cite{luo2022understanding,bishop2023} present a similar efficiency-based argument against using bottom-up inference in hierarchical latent variable models. 

We claim that efficiency arguments paint an incomplete picture; the main reason one should avoid bottom-up inference in hierarchical latent variable models is the lack of direct \textit{feedback} from the generative model. We argue that since the purpose of the inference model is to perform \textit{Bayesian inference} at any given layer in the hierarchy, it stands to reason that interleaving feedback from each transition in the generative model into each respective transition in the inference model can only make both the inference and generative models more aligned and accurate. Although this rationale may not apply to diffusion models in quite the same way as it applies to HVAEs, because the inference model of the former is typically fixed, the top-down latent hierarchy structure is nonetheless ubiquitous. Moreover, since the top-down posterior in diffusion models is tractable by definition, and follows the same topological ordering of the latent variables as the generative model, it can be used to specify the \textit{generative} model transitions by simply replacing the data in our conditioning set with a denoising model. This offers an intuitive view of diffusion models as a specific instantiation of ladder networks and/or HVAEs with top-down inference.

A major problem with VAEs and their hierarchical counterparts, which is not present in diffusion models, is the \textit{hole problem}. The hole problem refers to the mismatch between the so-called aggregate posterior (i.e. simply the average posterior distribution over the dataset) and the prior over the latent variables. As shown in Figure~\ref{fig: hole}, there can be regions with high probability density under the prior which have low probability density under the aggregate posterior. This then affects the quality of generated samples, as the decoder may be tasked with decoding latent variables sampled from regions not covered by the training data. Moreover, the higher the dimensionality of our input data, the less likely it is that our finite dataset covers the entirety of the input space. The manifold hypothesis posits that high-dimensional datasets lie along a much lower-dimensional latent manifold. However, since providing latent variable identifiability guarantees is very challenging for most interesting problems, in practice, we often resort to unfalsifiable assumptions about both the functional form and dimensionality of the latent space.

Diffusion models cleverly circumvent both of the aforementioned issues by: (i) defining the aggregate posterior to be equal to the prior by construction; and (ii) sacrificing the ability to learn reusable representations by fixing the posterior distribution according to a predefined noise schedule. The first point (i) ensures a smooth transition between the prior $p(\mathbf{z}_T)$ and the model $p(\mathbf{x} \mid \mathbf{z}_1)$, so we avoid sampling latent variables from regions of low density under the aggregate posterior $q(\mathbf{z}_T)$. The second point (ii) entails manually specifying how smooth this transition is by defining the latent variables $\mathbf{z}_{1:T}$ to simply be incrementally noisier versions of the input according to a judicious choice of noise schedule. This added noise can be interpreted as a kind of data augmentation technique, which helps smooth out the data density landscape and connect distant modes of the underlying data distribution. As explained in Section~\ref{subsubsec: weighted diffusion loss}, the noise schedule is specified by parameters $\alpha_t$, $\sigma^2_t$ and in combination with a weighting function $w(\alpha^2_t/\sigma^2_t)$, stipulates the relative importance of each noise level in the diffusion objective. It turns out that the main difference between most diffusion model objectives boils down to the \textit{implied} weighting function being used as a result~\citep{kingma2021variational,kingma2023understanding}. If our primary goal is high-quality sample generation, it suffices to adjust the noise schedule and weighting function such that the model focuses on perceptually important information and ignores imperceptible bits. Indeed, the majority of bits in images are allocated to imperceptible details and can in principle be ignored. Moreover, by encouraging the model to focus on some noise levels more than others, we are implicitly prescribing a preference for modelling low, mid, and/or high-frequency details at different noise levels.~\cite{ho2020denoising} found that although their diffusion models were not competitive with state-of-the-art likelihood-based models in terms of lossless codelengths, the samples were of high quality nonetheless. This demonstrates that diffusion models possess excellent inductive biases for image data.

Since the Markovian transitions between latent states $q(\mathbf{z}_t \mid \mathbf{z}_{t-1})$ are chosen to be linear Gaussian with isotropic covariances, the top-down posterior $q(\mathbf{z}_{t-1} \mid \mathbf{z}_{t}, \mathbf{x})$ is tractable through Gaussian conjugacy and the KL divergence terms in the associated VLB simplify significantly down to squared-error terms (Section~\ref{subsubsec: deriving dkl}). Given that the Gaussian diffusion process can be defined directly in terms of the conditionals $q(\mathbf{z}_t \mid \mathbf{x})$ (ref. Section~\ref{subsec: Gaussian Diffusion Process: Forward Time}), it is possible to: (i) train any level of the latent variable hierarchy independently of the others; (ii) share the same denoising model across the whole hierarchy. This constitutes a critical advantage over ladder networks and top-down HVAEs, as they both induce hierarchical dependencies between the latent states which prevent training individual layers independently. This advantage is particularly salient for infinitely deep latent variable hierarchies. As explained in detail in Section~\ref{sec: variational diffusion models}, diffusion models provide a principled framework for making the latent variable hierarchy infinitely deep. Such models are trained in continuous-time where $T \to \infty$, and can be shown to always improve the diffusion loss compared to hierarchical latent variable models like top-down HVAEs and discrete-time diffusion models~\citep{kingma2021variational} (ref. Section~\ref{subsubsec: on infinite depth}). It is also worth reiterating the ease with which it is possible to recast the denoising task in diffusion models in terms of noise prediction~\citep{ho2020denoising} rather than image prediction (see e.g. Section~\ref{subsec: Discrete-time Generative Model}), that noise prediction seems to perform better in practice, and that the resulting setup has close connections to score-based generative modeling~\citep{hyvarinen2005estimation,vincent2011connection,song2019generative,song2021scorebased}.

The success of diffusion models can be partly attributed to an additional reduction in \textit{degrees of freedom} compared to top-down HVAEs. In VAEs, several simplifying assumptions are made to ensure the inference problem is both tractable and scalable: (i) amortized variational inference; (ii) mean-field variational family assumption; (iii) assumed parametric distributions for both the prior and likelihood; (iv) stochastic optimization of a Monte Carlo estimator of the evidence lower bound. Given the close connection between top-down HVAEs and diffusion models established in Section~\ref{sec: variational diffusion models}, we can see that comparatively speaking diffusion models constitute yet another simplifying assumption by fixing the inference distribution to follow a pre-defined noise schedule. This transforms the learning problem from involving the minimization of the \textit{reverse} KL divergence to improve our posterior approximation: $\argmin_{q \in \mathcal{Q}}D_{\mathrm{KL}}( q(\mathbf{z}_{1:T} \mid \mathbf{x}) \parallel p(\mathbf{z}_{1:T}))$, where the prior $p$ may be fixed, to minimization of the \textit{forward} KL divergence: $\argmin_{p \in \mathcal{P}} D_{\mathrm{KL}}( q(\mathbf{z}_{1:T} \mid \mathbf{x}) \parallel p(\mathbf{z}_{1:T}))$, where the posterior $q$ is fixed:
%
\begin{align}
    \argmin_{p \in \mathcal{P}} D_{\mathrm{KL}}( q(\mathbf{z}_{1:T} \mid \mathbf{x}) \parallel p(\mathbf{z}_{1:T}))
    & = \argmin_{p \in \mathcal{P}} \mathbb{E}_{q(\mathbf{z}_{1:T} \mid \mathbf{x})} \left[-\log p(\mathbf{z}_{1:T}) \right] - \mathcal{H}(q(\mathbf{z}_{1:T} \mid \mathbf{x}))
    \\[0pt] & = \argmax_{p \in \mathcal{P}} \mathbb{E}_{q(\mathbf{z}_{1:T} \mid \mathbf{x})} \left[\log p(\mathbf{z}_{1:T}) \right] + c, \label{eq: erm}
\end{align}
which essentially amounts to a \textit{supervised learning} problem with noise-augmented i.i.d. data, optimized via maximum likelihood. Indeed, if all we care about is image synthesis quality, then it is intuitively advantageous to sacrifice the ability to learn reusable representations by fixing the posterior $q$ and focusing on leveraging the tried-and-tested machinery of supervised learning to train a good generative model. This rationale also motivated ladder networks~\citep{valpola2015neural}. Purely unsupervised learning methods try to represent \textit{all} the information about $p(\mathbf{x})$, which includes imperceptible details and complicates the learning problem. Conversely, supervised learning is effective at filtering out unnecessary information for the task at hand, which in combination with carefully weighted diffusion objectives, explains how/why diffusion models are capable of high-quality image synthesis that better aligns with human perception.

In Section~\ref{subsec: Understanding Diffusion Objectives}, we provided a deeper understanding of the various weighted diffusion objectives in literature. By further analyzing the objective in Equation~\ref{eq: erm}, it is possible to show that the diffusion loss is equivalent to the ELBO under simple data augmentation using Gaussian additive noise~\citep{kingma2023understanding}, so long as the weighting function $w(\lambda_t)$ is monotonically increasing w.r.t. time $t$. We showed that if $w$ is a valid CDF, then we can define a valid probability distribution $p_w(t)$ specified by the weighting function, which acts as a data augmentation kernel and dictates the importance of different noise levels as outlined by~\cite{kingma2023understanding}. However, multiple works report impressive image synthesis results using non-monotonic weighting functions~\citep{nichol2021improved, karras2022elucidating}, which somewhat peculiarly implies that the ELBO is being minimized at certain noise levels. This seems to reaffirm the widespread belief that maximum likelihood may not be the appropriate objective to use for high-quality sample generation. However,~\cite{kingma2023understanding} showed that likelihood maximization need not be intrinsically at odds with high-quality image synthesis, as they achieved state-of-the-art FID scores on the high-resolution ImageNet benchmark by optimizing the ELBO (under data augmentation).
% using a combination of monotonic weighting functions and architectural improvements proposed by~\cite{hoogeboom2022equivariant}.

We further argue that reconnecting weighted diffusion objectives with maximum likelihood (i.e. the ELBO) is particularly important because we know from Shannon's source coding theorem that the average codelength of the optimal compression scheme is the entropy of the data $\mathbb{\mathcal{H}}(X) = \mathbb{E}[-\log p(\mathbf{x})]$. Thus, as long as we are minimizing codelengths given by the information content $-\log p_{\boldsymbol{\theta}}(\mathbf{x})$ defined by a probabilistic model $p_{\boldsymbol{\theta}}$ (e.g. by maximizing likelihood), then the resulting average codelength $\mathbb{E}[-\log p_{\boldsymbol{\theta}}(\mathbf{x})]$ approaches the entropy of the true data distribution. This is the fundamental goal of generative modelling and compression, a goal with which maximum likelihood is well aligned.

To conclude, the success of diffusion models is arguably as much a product of collective engineering effort and scale as it is a product of algorithmic and theoretical insight. Nonetheless, identifying analogies between model classes undoubtedly aids in understanding, and recognizing the unique properties of specific models helps refine our intuitions about what may or may not work in the future. Fertile ground for future work includes enabling diffusion models to learn semantic latent representations, expanding forward diffusion processes beyond linear Gaussian transitions, and leveraging the identifiability guarantees of probability flow ODEs~\citep{song2021scorebased} for causal representation learning and inference.